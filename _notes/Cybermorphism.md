---
created: 2024-10-11T03:32:11.792Z
title: Cybermorphism
slug: cybermorphism
date: 2024-10-14
categories: []
---
> *"A graphic representation of data abstracted from the banks of every computer in the human system. Unthinkable complexity. Lines of light ranged in the nonspace of the mind, clusters and constellations of data."* ([Neuromancer](https://www.google.com.sg/books/edition/Neuromancer/vi2KCwAAQBAJ?hl=en&gbpv=1&printsec=frontcover))

Imagine a future where the boundaries between human and machine blur - a world where our minds extend beyond our biological limits, seamlessly integrating with technology. This isn’t science fiction; it’s happening now.

I've lived most of my life experimenting with this human-machine interface, taking me from game development to brain-computer interfaces and cyborgism. In this post, I'll share the philosophical project, how we expand our cognition and how the 21st century will change consciousness.

Let's dive in.

![[Pasted image 20241014002141.png]]
*The [XREAL AR glasses](https://us.shop.xreal.com/products/xreal-air-2-pro) running through my [Jelly Star](https://kran.ai/jelly) with the [Beam stabilizer](https://us.shop.xreal.com/products/xreal-beam)[^1]*

[^1]: While writing this post fully in these same glasses, I notice the Beam Pro seems to have come out along with another iteration of the XREAL Air 2 Ultra glasses. I think my bank account will cry soon.

## Cybermorphism

The concept of cybermorphism is inspired by the extended mind thesis, _Neuromancer_ and "tools for thought". It's about expanding cognition, reaching beyond our 20th century cognition and creating a tech-enabled existence.

Cognition is always a moving goalpost and it changes much more than we care to think. Twenty years ago, no one used social media and now we check out phones [159](https://explodingtopics.com/blog/social-media-usage) times per day, changing how attention and cognition work. Books weren't readily available before the [15th century](https://en.wikipedia.org/wiki/Printing_press) and even then, free speech only arose in the [19th century](https://www.freespeechhistory.com/2019/11/21/episode-34-the-age-of-reaction-the-fall-and-rise-of-free-speech-in-19th-century-europe/). 

![[Pasted image 20241014005709.png]]
*The NIRSport2 SoTA fNIRS neuroimaging headset ([timelapse](https://youtu.be/5rnJgt_Xu-Q))*

As a result, you might argue that the common person's cognition before the 19th century was both more limited by lack of diverse intellectual input (pre-training) and by lack of expression (rewarded behavior), leading to a [lack of original cognition](https://en.wikipedia.org/wiki/Newspeak).

Now, whenever I talk with people born with the internet, I'm surprised at how informed and expressive they are. I don't think the previous generations could have [matched up at the same age](https://www.sciencedirect.com/topics/psychology/flynn-effect#:~:text=Abstract,approximately%203%20points%20per%20decade.). 
Historically, technology has been the enabler of cognition and we're finding more and more ways to design [tools for thought](https://numinous.productions/) to augment our brains.

Hence, **cybermorphism does not expect this trend of cognition improvement to stop**.

A good example of technology embracing the [extended mind thesis](https://academic.oup.com/analysis/article-abstract/58/1/7/153111?redirectedFrom=fulltext&login=false) (the idea that our cognition extends beyond our brain and into our tools) is [Obsidian](https://obsidian.md/). Our brain seems to think in concepts connected by neural pathways and not in information hierarchies like documentation systems and Obsidian embraces this.

![[Pasted image 20241014014105.png]]
*Each dot on the left is a page in my second brain with two examples of page text on the right - pink links represent references to other pages*

Similarly, we find that cybermorphosis changes between generations. The same people who grew up with the internet now [don't know what files are](https://www.theverge.com/22684730/students-file-folder-directory-structure-education-gen-z). It's all `cmd + k`, Spotlight and apps. 

Hierarchical file systems are great at managing documents but it might not *actually* be the best way to *work with concepts*. [Alfred](https://www.alfredapp.com/) is a Spotlight replacement that gives you an instant search field to your complete file system along with any extensions you want. It is the ultimate in file system independence.

## Brain cycles / action
Something you might notice with the above examples is that in cybermorphism, we're quite concerned with **how many brain cycles we need to use for each cognitive act**.

Similar to the maxims of engineering, we improve cognition by 1) removing unnecessary steps, 2) simplifying or optimizing and 3) automating. Sometimes, others have automated it for us, helping a lot (read: *all software*). 

Replacing file systems removes unnecessary hierarchical information navigation (est. 5 seconds), second brain note-taking replaces the need for strictly organized note-taking systems (est. 3 minutes per note) and [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) automates completing a project (est. $$\infty$$). Similarly, my hardware setups are usually optimized for easy access across the 20+ programs I use on a daily basis.

![[XREAL_1.gif]]
*Live view of my XREAL AR virtual monitor interface*

Of course, improving cognition isn't just about optimizing a specific process. Most of it will be about *creating new cognitive abilities*.
## Creating more senses
Now that we know our brain is spread across our internal neural circuitry and our tools, we might ask ourselves *"can we implement new features for this brain?"* Of course!

The best example of such a feature is **the keyboard**. A [new limb](https://x.com/EsbenKC/status/1844620047182070262) for extended cognition that depends on our brain recoding our fingers' specialization.

For people with reduced bodily function (such as [paraplegics](https://www.sciencedirect.com/topics/medicine-and-dentistry/paraplegia) and [Stephen Hawking](https://www.washington.edu/doit/dr-stephen-hawking-case-study-using-technology-communicate-world#:~:text=By%20squeezing%20his%20cheek%20muscles,speak%22%20through%20a%20voice%20synthesizer.)), these new modalities of action (so-called "external effectors") enable them to live a semi-normal life. And while Hawking in the early 2010s used the few muscles he could still control in a clever way to communicate, today's Neuralink enables [Noland Arbaugh to pull Civ VI all-nighters](https://www.reddit.com/r/civ/comments/1ctgui8/noland_arbaugh_using_neuralink_to_play_civ6/). The progress here is insane.

![[Pasted image 20241014012236.png]]
*Me calibrating the EyeLink 1000, a 1,000 hz 0.15° accuracy eye tracker*

I still remember when we received a grant to purchase the (very expensive) [NIRSport2](https://nirx.net/nirsport) for our lab which was the state-of-the-art fNIRS neuroimaging equipment at the time. About a week after we received it, the revolutionary [Kernel Flow](https://www.kernel.com/products) came out, shaking up the field completely.

Of course, besides my endless 4am sessions in the lab with the amazing NIRSport2, I ended up playing with the beta Kernel Flow through a Canadian Lab I connected with in our NeuroTechX network. This is one of the reasons why I'm connected with humanity's most experimented upon man and original founder of Kernel, [Bryan Johnson](https://www.standard.co.uk/lifestyle/wellness/bryan-johnson-anti-aging-biological-age-son-longevity-b1139278.html), on LinkedIn.

## Aside: The science behind cognition

Without understanding the brain, we cannot understand how to develop and research cybermorphism. This is a very short primer on cognition for the initiated:

We know surprisingly little about how cognition works. With the technical baggage from the incumbent outside-in perspective on which functions the brain encodes (thanks, psychology), many theories still need evidence before we can verify them.

One of the best ways to think of the neocortex (our main tool in cybermorphism) is as a collection neural networks connected by wires in useful ways. 

Specifically, think of it as [52 distinct neural network architectures](https://en.wikipedia.org/wiki/Brodmann_area) (illustrative) designed through evolution for various functions, each with different inputs and outputs. Some receive audio input, some visual input and some receive input from other areas of the brain.

Each of these areas can be modeled separately as an "inside-out" process. Similar to the famous ["What is it like to be a bat?"](https://philpapers.org/go.pl?id=NAGWII&proxyId=&u=http%3A%2F%2Fwww.jstor.org%2Fstable%2Fpdfplus%2F2183914.pdf), you should now imagine what it is like to be that neural network.
- You receive signals of unknown origin in an unknown format that you are somewhat familiar with by design.
- If your output is useful for predicting the next second or minute (so-called ["predictive coding"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6632880/)), you get a reward.
- You begin to update your transformation of these inputs to get the best rewards.

Traditionally, cognitive psychology has tried to find the neural representations of abilities such as "reasoning", "will" and "emotions". These come from the 1890 book ["The Principles of Psychology"](https://psychclassics.yorku.ca/James/Principles/index.htm) which at the time was a revolutionary book. However, it is outdated now.

![[Pasted image 20241014011734.png]]
*"How much hardware do you want for your cybermorphosis?" "Yes." (the [NIRSport2](https://nirx.net/nirsport) after the 30 minute setup process, ready to capture brain signals)*

As you imagine what it is like to be a neural network in the brain, you will realize that you have no clue what "reasoning", "will" or "emotions" are and simply do what is optimal, e.g. model "time" as a sequence similar to how you would model "a series of location", meaning that these are not two different types of encodings[^2].

[*2]: See e.g. this figure I made for a paper studying neural augmentation of a simulated robot that has to learn how its own limbs function. 
	![[Pasted image 20241014163238.png]]

For more context, I highly recommend reading the book ["The Brain From Inside Out"](https://academic.oup.com/book/35081). If you're already in the literature of the brain, ["The Continuity of Mind"](https://global.oup.com/academic/product/the-continuity-of-mind-9780195370782) should be of interest to shake up your thinking.

## Aside 2: The brain easily learns new abilities

One of the seminal papers on brain-machine interfacing was the [2000 paper by Chapin and others](https://www.nature.com/articles/nn0799_664). They got a rat to control a water dispenser simply through neural activation. With a neural network, they modeled which neurons activated when the rat pulled a lever, used that model to activate the water dispenser when these neurons fired and the rats ended up learning how to control the water dispenser just with their mind.

However, it turns out that we don't need the computer to do any coding at all. We can simply say "when this neuron fires, we pull the lever" and the brain will quickly learn how to activate that specific neuron at the correct time to receive the right feedback from its environment. Of course, implementing learning on both sides of that system helps the process along.

I highly recommend the [short paper from Neuralink](https://www.jmir.org/2019/10/e16194/) detailing how they record neural activity.

![[Pasted image 20241014005626.png]]
*My profile's YouTube cover image of 3 years is the MRI recording of my [T1 scan](https://radiopaedia.org/articles/t1-weighted-image) seen on my [About page](https://blog.kran.ai/about)*

## The future of cognition
If you're like me and ended up in brain-computer interfacing research as a result of cybermorphism, you probably also ended up working with software after realizing that brain-computer interfaces were too immature[^3]

[^3]: At an event in San Francisco I was made privy to the inside stories of funding for brain augmentation and it doesn't look good. There's no funding except for pharmaceutical interventions that have American insurance companies as customers. As a result, the only progress has been slow ([Blackrock Neurotech](https://blackrockneurotech.com/products/utah-array/#:~:text=What%20is%20the%20Utah%20Array,degree%20of%20precision%20and%20accuracy.) and [Nirx](https://nirx.net/)), self-funded (see [Musk](https://neuralink.com/) and [Johnson](https://kernel.co/)) or from [the military](https://www.from-the-interface.com/DARPA-funding-BCI-research/) (yuck).

Today, however, the hardware space is changing more than ever.
### Cybermorphic hardware
For me, cybermorphic hardware comes in many forms:
- Multi-channel invasive neural implants for direct neural interaction (such as Neuralink)
- Redesigned keyboards with new types of mapping to improve [WPM](https://en.wikipedia.org/wiki/Words_per_minute)
- Direct current stimulation to key areas of the brain using tDCS devices
- AR and VR glasses designed to improve how we interact with our extended mind
- New external effectors such as bionic limbs and prosthetics

I'll give my quick take on brain-computer interfaces first:
- **Brain reading:** The only consumer hardware for neural interfacing that will be useful will be invasive hardware like the Neuralink, the Utah Array or ECoG and non-invasive neuroimaging will be seen as too imprecise for direct control. 
- **Brain stimulation:** tDCS and TMS will not be adopted for augmenting neural function outside clinical settings without being dangerous or simply not useful. Again, invasive neural stimulation will win out.

![[Pasted image 20241014012320.png]]
*Sending direct current through my brain with the PlatoWork tDCS beta device from my friends over at [PlatoScience](https://www.platoscience.com/pages/product)*

I personally use the XREAL Air 2 Pro glasses and there is an incredible immersion in a virtual monitor setup. I wrote my thesis completely in the Oculus Link interface on my Quest II. This will only become more normal and I expect these devices to become miniaturized and more useful in everyday life.

I'll be very curious to see how our interfaces with computers change from text to neural, voice or gesture. How file systems will change into something even more exciting (maybe even the cyberspace from Neuromancer and cyberpunk fame). Using shortcuts is something completely ingrained for me but maybe these will become useless as AI changes how each button works.

With projects such as [Blueprint](https://blueprint.bryanjohnson.com/?srsltid=AfmBOooG5JBooJc7gypSscc0tJTvMs3QFxASTQMOgCd-DNkdcfwH2Hv1) and the development of [accurate body sensory hardware](https://www.youtube.com/thequantifiedscientist), it will be interesting to see how our interfaces will respond and track our bodily states. I imagine emotional modeling and stress response from our software will become commonplace since it's in many ways the next frontier of interface design.

Last but not least, robots will be a thing and take away much of the need for us to do menial labor. This of course comes with a much-needed introspection on how much risk we're willing to take by inviting superintelligent agents into our home and lives.
### Predictions: Cybermorphic brain augmentation

 To make the above statements more concrete, I'll share my quantitative predictions for the next 35 years: 
 
- Within ten years, Neuralink will be available for healthy consumers, either privately or publicly (80%).
- Pharmaceutical brain augmentation (whether nanobots or drugs, excluding caffeine, nicotine and pseudoscience) will be commonplace and estimated at 1%< use within the working population by 2035 (90%).
- Integrated biometric tracking (e.g. glucose measurement devices, watches do not count) will be commonplace (1%< of the US population) by 2030 (80%).
- Consumer AR glasses will become commonplace (1% adoption) for public wear by 2030 (75%).
- The _consumer interface_ with machines, independent of platform, will _not_ be by text in 2035 (80%). Gesture or voice are the expected contenders but I won't leave direct-to-neural out of the race.
- Apple Vision Pro will be seen as a _financial_ flop (if it isn't already) in a year (95%).
- Neural brain augmentation using external hardware will be commonplace (1%< of the US population) by 2040 (80%).
- Sensory augmentation (e.g. magnetic field sensors, wider color spectrum and cyberspace connection) will be commonplace (1%< of US population) by 2040 (70%).
- Networked human-mind interfaces between multiple humans will be possible by 2060 (60%).
- A complete human brain upload with confirmation of the retention of memories and general cognitive ability (barring designed augmentation) will be completed before 2060 (40%).

### AI cybermorphism: Cyborgism
[Cyborgism](https://cyborgism.wiki/) is the branch of cybermorphism whose practitioners dedicate their minds and brains to interfacing with AI. It's the group that consistently has the most understanding of what AIs are capable of and the group that develops the most advanced interfaces with LLM latent spaces. Their original goal was to use AI to assist with ambitious alignment research, though it seems like they have instead dived deeper into combining their cognition with AI.

This is awesome. I expect cyborgism to be the frontier of the most useful and interesting cybermorphic interaction and convergence with AI.

![[Pasted image 20241014171721.png]]
*[The Loom](https://generative.ink/posts/loom-interface-to-the-multiverse/) - an interface into the multiverse of LLM completions*

As an AI safety researcher, I've drunk the Kool-Aid that AI will be transformative for society. In [Rob Bensinger's words](https://x.com/robbensinger/status/1801306833325592759), I'm an AGI alarmist. I expect AGI to bring immense good and have the potential to destroy society. I also expect that we can solve most of the issues with some globally ambitious engineering.

Of course, this means I expect **extreme** implications for our shared conscious experience and global cognition from the introduction of AI. Programming tutorials are not necessary anymore because you can just ask an LLM for a study plan. Companies are replacing incumbent software because it has become so easy to develop in-house solutions. Everyone can have a PhD student in their pocket to answer any question. The democratization of knowledge is being finalized.

I'll leave much of the speculations on how we as humans can engage meaningfully with superintelligent AI for other posts but suffice to say that cyborgism will be a big part of cybermorphism in the future.

### Predictions: Where AI will be in ten years

Again, let me back up the above discussion with concrete predictions that also go beyond cybermorphism:

- Open weights models will catch up to end-2025 performance, even to o1, at the end of 2026. With this, private models will begin to be developed (65%).
- Most human-like internet activity (browsing, information gathering, app interaction) will be conducted by agents in 2030 (90%).
- Within a year, we'll have GPT-5 (...or equivalent) (80%) which will upend the agent economy, creating a slow internet (or the expectation thereof), where every action needs checking and security to avoid [cyber offense risks](https://cybercapabilities.org/) and tragedies of the commons (70%).
- Trillions of persistent generally intelligent agents will exist on the web by 2030 (90%), as defined by unique memory-persistent instantiations of an arbitrary number of agent types.
- A sentient and fully digital lifeform will be spawned before 2035, irrespective of the rights it receives (99% and I will argue my case).
- Despite the tele-operated robots at the "We, Robot" event, the Optimus bot will be seen as the most capable personal robotic platform by 2028 (30%) (and I will own one; conditional 90%).
- Before 2035, we will reach something akin to a singularity; a 20% US GDP growth year-over-year, two years in a row, largely driven by general intelligence (30% probability, highly dependent on the perpetuity of US democracy).
- Biometric authentication will be the de-facto 2FA for most password-protected systems (70%). Iris scanners will be available on your "edge device" (whether phone or AR device; conditional 50%).
- The web (50%< of ISP traffic) will have federated or decentralized identity controls that tracks and ensures actions are done by humans before 2035 (75%).
### Become a Cybermorphic

If you've read all the way to here, I hope you feel inspired to join me! Cybermorphics are of all ages and emerge from the founders of computer science and the Islamic scholars of the 1500s to today's AI tech founders and internet natives.

Having worked with and talked with many cybermorphics (Chalmers, Buzsaki, Janus, Johnson, Nielsen, among others), I know they are all curious and conscientious individuals with visions for where we're going.

The future of cognition looks incredibly exciting and the status quo has never seemed more malleable than now. 

Godspeed.

## Reading list
With this introduction, I don't want to leave you without anything to lead you down the rabbit hole. The non-fiction:
- [ReadingWhatWeCan](https://readingwhatwecan.com/): This is a reading list I made for people to understand where AI is going. The first text by Vernor Vinge is especially good and succinct.
- [Tools for Thought](https://numinous.productions/ttft/): This is an exploration of how we might develop tools for thought from Andy Matuschak and Michael Nielsen. You will find Andy on the internet and Michael in various podcasts talking about this concept as well.
- [The Extended Mind](https://academic.oup.com/analysis/article-abstract/58/1/7/153111?redirectedFrom=fulltext&login=false): Foundational reading. Important to understand the philosophical underpinnings, as defined by Andy Clark and David Chalmers.
- [The Brain from Inside Out](https://academic.oup.com/book/35081): A great book by the amazing neuroscientist György Buzsáki. Should be accessible to most tech-savvy or academically minded individuals but gives you the foundation to understand how we rewire our brains along with some of the history of brain sciences.
- [Hacker's Manifesto](https://phrack.org/issues/7/3.html): Written by a cringe-y teen in the 80s after his arrest for hacking the school network, this became a cult classic for what hackers were really about.

And the fiction:
- [Neuromancer](https://www.goodreads.com/book/show/6088007-neuromancer): Probably one of the better depictions of what a cyberspace-enabled existence in a dystopian future looks like, this book combines untasteful culture with imaginings of what our interaction with cyberspace might be like.

There's plenty more where these come from but I'll leave it at that. A lot of cybermorphic cultural heritage also extends from gender theory (abolishing static identities), accelerationism (the Nick Land type) and the early internet writings about what a decentralized web could really *be* for human identity.

> Like swarms of avatars subsisting on a star  
> Desiccant souls in searing light exposed  
> Moths to the raging inferno of the binary
> *[Cybermorphism / Mainframe](https://youtu.be/1LQfI_H5nBg)*
