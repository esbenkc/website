---
title: The AI Safety Tech Tree
slug: aisafetytechtree
categories:
  - research
  - AI safety
location: In the car to Mabul Island
---
No one knows what the end game of safe AI looks like.

We all know that artificial general intelligence (AGI) will bring about [unprecedented](https://ia.samaltman.com/) [opportunity](https://darioamodei.com/machines-of-loving-grace), solve all of the world's problems, bring about a new world, etc. etc...

However, we obviously run a [massive risk](https://time.com/6283958/darwinian-argument-for-worrying-about-ai/) by introducing a [stronger, better, and more numerous species of intelligence](https://stuff.kajsotala.fi/Papers/DigitalAdvantages.pdf) into the world.

Plenty of people have explored what it requires to make AI safe. However, I feel like they often aren't concrete on the technical details.

In this post, I'll explore what an end game of safe AI might look like and crucially, how we can get there.

## End games
We're 

## The risks
To properly understand what the final outlook of AI might look like, let's take a short overview of the risks we're running in developing a superintelligence:
- Even with aligned AI, we run the risk of extreme centralization of power and potential "value lock-in", a situation where values and systems aren't changing, due to incumbents remaining in control.



As an AI safety researcher, I've drunk the Kool-Aid that AI will be transformative for society. In [Rob Bensinger's words](https://x.com/robbensinger/status/1801306833325592759), I'm an AGI alarmist. I expect AGI to bring immense good and have the potential to destroy society. I also expect that we can solve most of the issues with some globally ambitious engineering.


## Predictions for AI
Again, let me back up the above discussion with concrete predictions that also go beyond cybermorphism:

- Open weights models will catch up to end-2025 performance, even to o1, at the end of 2026. With this, private models will begin to be developed (65%).
- Most human-like internet activity (browsing, information gathering, app interaction) will be conducted by agents in 2030 (90%).
- Within a year, we'll have GPT-5 (...or equivalent) (80%) which will upend the agent economy, creating a slow internet (or the expectation thereof), where every action needs checking and security to avoid [cyber offense risks](https://cybercapabilities.org/) and tragedies of the commons (70%).
- Trillions of persistent generally intelligent agents will exist on the web by 2030 (90%), as defined by unique memory-persistent instantiations of an arbitrary number of agent types.
- A sentient and fully digital lifeform will be spawned before 2035, irrespective of the rights it receives (99% and I will argue my case).
- Despite the tele-operated robots at the "We, Robot" event, the Optimus bot will be seen as the most capable personal robotic platform by 2028 (30%) (and I will own one; conditional 90%).
- Before 2035, we will reach something akin to a singularity; a 20% US GDP growth year-over-year, two years in a row, largely driven by general intelligence (30% probability, highly dependent on the perpetuity of US democracy).
- Biometric authentication will be the de-facto 2FA for most password-protected systems (70%). Iris scanners will be available on your "edge device" (whether phone or AR device; conditional 50%).
- The web (50%< of ISP traffic) will have federated or decentralized identity controls that tracks and ensures actions are done by humans before 2035 (75%).